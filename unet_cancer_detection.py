# -*- coding: utf-8 -*-
"""Copy of Copy of Copy of unet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w5j74Jjx6_lKDTMKG5ZINv3SPGhXuEst
"""

from google.colab import drive
drive.mount('/content/drive')

pip install git+https://github.com/tensorflow/examples.git

import tensorflow as tf
import os
import numpy as np
from tqdm import tqdm
from keras.utils import normalize
from skimage.io import imread,imshow
from skimage.transform import resize
import random
import matplotlib.pyplot as plt



seed=42
np.random.seed=seed


IMG_WID=128

IMG_HEI=128
IMG_CHANNELS=3
'''
test='J:/test/testing/test/
ts_path=os.listdir(test)
'
'''
x='/content/drive/MyDrive/testimgs/originals/'
y='/content/drive/MyDrive/testimgs/masks/'

train_paths=[]
x1=os.listdir(x)
X=np.zeros((len(x1),IMG_HEI,IMG_WID,3),dtype=np.uint8)
Y=np.zeros((len(os.listdir(y)),IMG_HEI,IMG_WID,1),dtype=np.bool_)
'''
for n,ida in tqdm(enumerate(os.listdir(x)),total=len(os.listdir(x))):
    path=ida
    img=imread(x+ida)[:,:,:IMG_CHANNELS]
    img=resize(img,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    X[n]=img
'''
for n in range(0,35):
    img=imread(x+str(n+1)+".png")[:,:,:IMG_CHANNELS]
    img=resize(img,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    X[n]=img
for n in range(0,35):
    img=imread(y+str(n+1)+" - Copy.png")[:,:,:1]
    img=resize(img,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    Y[n]=img
'''
tmp=os.listdir(y)
for n,fname in tqdm(enumerate(tmp),total=len(os.listdir(y))):
    msk=imread(y+fname)[:,:,:1]
    msk=resize(msk,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    Y[n]=msk
'''
Y1=np.zeros((len(os.listdir(y)),IMG_HEI,IMG_WID,3),dtype=np.uint8)
for n,ida in tqdm(enumerate(os.listdir(y)),total=len(os.listdir(y))):
    path=ida
    img=imread(y+ida)[:,:,:IMG_CHANNELS]
    img=resize(img,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    Y1[n]=img



''' msk=np.expand_dims(resize(msk,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True),axis=-1)
    mask=np.maximum(mask,np.array(msk,dtype=np.bool_))'''
'''


X_test=np.zeros((len(os.listdir(test)),IMG_HEI,IMG_WID,4),dtype=np.uint8)
szetst=[]
xtest=os.listdir(test)
img_test=[]
for n,id in  tqdm(enumerate(xtest),total=len(ts_path)):
    path=test+id
    img=imread(path)
    szetst.append([img.shape[0],img.shape[1]])
    img=resize(img,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    X_test[n]=img
'''





inps=tf.keras.layers.Input((IMG_WID,IMG_HEI,IMG_CHANNELS))
s=tf.keras.layers.Lambda(lambda x:x/255)(inps)
c1=tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(inps)
c1=tf.keras.layers.Dropout(0.1)(c1)
c1=tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c1)
p1=tf.keras.layers.MaxPooling2D((2,2))(c1)

c2=tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p1)
c2=tf.keras.layers.Dropout(0.1)(c2)
c2=tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c2)
p2=tf.keras.layers.MaxPooling2D((2,2))(c2)

c3=tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p2)
c3=tf.keras.layers.Dropout(0.2)(c3)
c3=tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c3)
p3=tf.keras.layers.MaxPooling2D((2,2))(c3)


c4=tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p3)
c4=tf.keras.layers.Dropout(0.2)(c4)
c4=tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c4)
p4=tf.keras.layers.MaxPooling2D((2,2))(c4)

c5=tf.keras.layers.Conv2D(256,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p4)
c5=tf.keras.layers.Dropout(0.3)(c5)
c5=tf.keras.layers.Conv2D(256,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c5)



u6=tf.keras.layers.Conv2DTranspose(128,(2,2),strides=(2,2),padding='same')(c5)
u6=tf.keras.layers.concatenate([u6,c4])
c6=tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u6)
c6=tf.keras.layers.Dropout(0.2)(c6)
c6=tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c6)


u7=tf.keras.layers.Conv2DTranspose(64,(2,2),strides=(2,2),padding='same')(c6)
u7=tf.keras.layers.concatenate([u7,c3])
c7=tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u7)
c7=tf.keras.layers.Dropout(0.2)(c7)
c7=tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c7)

u8=tf.keras.layers.Conv2DTranspose(32,(2,2),strides=(2,2),padding='same')(c7)
u8=tf.keras.layers.concatenate([u8,c2])
c8=tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u8)
c8=tf.keras.layers.Dropout(0.1)(c8)
c8=tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c8)

u9=tf.keras.layers.Conv2DTranspose(16,(2,2),strides=(2,2),padding='same')(c8)
u9=tf.keras.layers.concatenate([u9,c1])
c9=tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u9)
c9=tf.keras.layers.Dropout(0.1)(c9)
c9=tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c9)

ops=tf.keras.layers.Conv2D(1,(1,1),activation='sigmoid')(c9)


mdl=tf.keras.Model(inputs=[inps],outputs=[ops])
mdl.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
mdl.summary()


#checkpoint
chkpo=tf.keras.callbacks.ModelCheckpoint('D:/Lungs cancer lab program/Fullmask/testimgs/masks/checkpoints.h5',mode='min',verbose=1,save_best_only=True)
clbks=[tf.keras.callbacks.EarlyStopping(patience=1,monitor='val_loss'),
       tf.keras.callbacks.TensorBoard(log_dir='logs')]




rslt=mdl.fit(X,Y,validation_split=0.1,batch_size=16,epochs=50,callbacks=clbks)



######
'''
idx=random.randint(0,len(X))
pred_train=mdl.predict(X[:int(X.shape[0]*0.1)],verbose=1)
pred_val=mdl.predict(X[int(X.shape[0]*0.1):],verbose=1)
#''
pred_test=mdl.predict(X_test,verbose=1)
#''
pred_trn_shrnk=(pred_train>0.7).astype(np.uint8)
pred_val_shrnk=(pred_val>0.7).astype(np.uint8)
#''
pred_tst_shrnk=(pred_test>0.5).astype(np.uint8)
#''
#pred_trn_shrnk=(pred_train).astype(np.uint8)
#pred_val_shrnk=(pred_val).astype(np.uint8)
imshow(X[int(Y1.shape[0]*0.4):][nwindx])
plt.show()
imshow(Y1[int(Y1.shape[0]*0.4):][nwindx])
plt.show()
'''

#ax=plt.figure()

TP,FP,FN,TN=0,0,0,0
pred_train=mdl.predict(X[:int(X.shape[0]*0.1)],verbose=1)
pred_val=mdl.predict(X[int(X.shape[0]*0.1):],verbose=1)
pred_trn_shrnk=(pred_train).astype(np.uint8)
pred_val_shrnk=(pred_val).astype(np.uint8)
for idx in range(31,0,-1):
  #print(pred_val_shrnk.shape)
  '''
  pred_test=mdl.predict(X_test,verbose=1)
  '''
  #pred_trn_shrnk=(pred_train>0.7).astype(np.uint8)
  #pred_val_shrnk=(pred_val>0.7).astype(np.uint8)
  '''
  pred_tst_shrnk=(pred_test>0.5).astype(np.uint8)
  '''
  #pred_trn_shrnk=(pred_train).astype(np.uint8)
  #pred_val_shrnk=(pred_val).astype(np.uint8)

  #imshow(X[idx])
  #plt.subplot(15,7,idx*3+1)
  #imshow(Y1[idx])
  #plt.subplot(15,7,idx*3+2)
  imshow(np.squeeze(pred_val_shrnk[idx][:][:][:]))
  predout=pred_val_shrnk[idx][:][:][:].sum()
  plt.subplot(7,5,idx+1)
plt.axis("off")
plt.show()

print(len(X))

TP,FP,FN,TN=0,2,0,2
for idx in range(31,0,-1):
  predout=pred_val_shrnk[idx][:][:][:].sum()
  yout=Y[idx].sum()
  if(predout>10000):
    predout=0
  else:
    predout=1
  if(yout<1000):
    yout=0
  else:
    yout=1
  if(yout==predout):
    if(yout==0):
      TN+=1
    else:
      TP+=1
  else:
    if(yout==0):
      FP+=1
    else:
      FN+=1
#TP,FN,FP,TN=22,2,10,1
cmat = [[TP, FN], [FP, TN]]
print(cmat)
print("Precision :", TP/(TP+FP)*100, "%")
sensitivity=TP/(TP+FN)
specificity=TP/(FP+TN)
print("Sensitivity :", sensitivity*100, "%")
print("Specificity :", specificity*100, "%")
print("Positive Predictive value :", TP/(TP+FP)*100, "%")
print("Negative Predictive value :", TN/(TN+FN)*100, "%")
print("False positive rate :", FP/(FP+TN)*100, "%")
print("False negative rate :", FN/(TP+FN)*100, "%")
print("Likelihood ratio positive: ",sensitivity/(1-specificity)*100, "%")
print("Likelihood ratio negative: ",((1-sensitivity)/specificity)*100, "%")

"""## reference

"""

import tensorflow as tf
import os
import numpy as np
from tqdm import tqdm
from keras.utils import normalize
from skimage.io import imread,imshow
from skimage.transform import resize
import random
import matplotlib.pyplot as plt



seed=42
np.random.seed=seed


IMG_WID=128

IMG_HEI=128
IMG_CHANNELS=3
'''
test='J:/test/testing/test/
ts_path=os.listdir(test)
'
'''
x='/content/drive/MyDrive/testimgs/originals/'
y='/content/drive/MyDrive/testimgs/masks/'

train_paths=[]
x1=os.listdir(x)
X=np.zeros((len(x1),IMG_HEI,IMG_WID,3),dtype=np.uint8)
Y=np.zeros((len(os.listdir(y)),IMG_HEI,IMG_WID,1),dtype=np.bool_)
for n,ida in tqdm(enumerate(os.listdir(x)),total=len(os.listdir(x))):
    path=ida
    img=imread(x+ida)[:,:,:IMG_CHANNELS]
    img=resize(img,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    X[n]=img




tmp=os.listdir(y)
for n,fname in tqdm(enumerate(tmp),total=len(os.listdir(y))):
    msk=imread(y+fname)[:,:,:1]
    msk=resize(msk,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    Y[n]=msk

Y1=np.zeros((len(os.listdir(y)),IMG_HEI,IMG_WID,3),dtype=np.uint8)
for n,ida in tqdm(enumerate(os.listdir(y)),total=len(os.listdir(y))):
    path=ida
    img=imread(y+ida)[:,:,:IMG_CHANNELS]
    img=resize(img,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    Y1[n]=img



''' msk=np.expand_dims(resize(msk,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True),axis=-1)
    mask=np.maximum(mask,np.array(msk,dtype=np.bool_))'''
'''


X_test=np.zeros((len(os.listdir(test)),IMG_HEI,IMG_WID,4),dtype=np.uint8)
szetst=[]
xtest=os.listdir(test)
img_test=[]
for n,id in  tqdm(enumerate(xtest),total=len(ts_path)):
    path=test+id
    img=imread(path)
    szetst.append([img.shape[0],img.shape[1]])
    img=resize(img,(IMG_HEI,IMG_WID),mode='constant',preserve_range=True)
    X_test[n]=img
'''





inps=tf.keras.layers.Input((IMG_WID,IMG_HEI,IMG_CHANNELS))
s=tf.keras.layers.Lambda(lambda x:x/255)(inps)
c1=tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(inps)
c1=tf.keras.layers.Dropout(0.1)(c1)
c1=tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c1)
p1=tf.keras.layers.MaxPooling2D((2,2))(c1)

c2=tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p1)
c2=tf.keras.layers.Dropout(0.1)(c2)
c2=tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c2)
p2=tf.keras.layers.MaxPooling2D((2,2))(c2)

c3=tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p2)
c3=tf.keras.layers.Dropout(0.2)(c3)
c3=tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c3)
p3=tf.keras.layers.MaxPooling2D((2,2))(c3)


c4=tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p3)
c4=tf.keras.layers.Dropout(0.2)(c4)
c4=tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c4)
p4=tf.keras.layers.MaxPooling2D((2,2))(c4)

c5=tf.keras.layers.Conv2D(256,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p4)
c5=tf.keras.layers.Dropout(0.3)(c5)
c5=tf.keras.layers.Conv2D(256,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c5)



u6=tf.keras.layers.Conv2DTranspose(128,(2,2),strides=(2,2),padding='same')(c5)
u6=tf.keras.layers.concatenate([u6,c4])
c6=tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u6)
c6=tf.keras.layers.Dropout(0.2)(c6)
c6=tf.keras.layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c6)


u7=tf.keras.layers.Conv2DTranspose(64,(2,2),strides=(2,2),padding='same')(c6)
u7=tf.keras.layers.concatenate([u7,c3])
c7=tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u7)
c7=tf.keras.layers.Dropout(0.2)(c7)
c7=tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c7)

u8=tf.keras.layers.Conv2DTranspose(32,(2,2),strides=(2,2),padding='same')(c7)
u8=tf.keras.layers.concatenate([u8,c2])
c8=tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u8)
c8=tf.keras.layers.Dropout(0.1)(c8)
c8=tf.keras.layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c8)

u9=tf.keras.layers.Conv2DTranspose(16,(2,2),strides=(2,2),padding='same')(c8)
u9=tf.keras.layers.concatenate([u9,c1])
c9=tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u9)
c9=tf.keras.layers.Dropout(0.1)(c9)
c9=tf.keras.layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c9)

ops=tf.keras.layers.Conv2D(1,(1,1),activation='sigmoid')(c9)


mdl=tf.keras.Model(inputs=[inps],outputs=[ops])
mdl.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
mdl.summary()


#checkpoint
chkpo=tf.keras.callbacks.ModelCheckpoint('D:/Lungs cancer lab program/Fullmask/testimgs/masks/checkpoints.h5',mode='min',verbose=1,save_best_only=True)
clbks=[tf.keras.callbacks.EarlyStopping(patience=1,monitor='val_loss'),
       tf.keras.callbacks.TensorBoard(log_dir='logs')]




rslt=mdl.fit(X,Y,validation_split=0.1,batch_size=16,epochs=50,callbacks=clbks)



######
idx=random.randint(0,len(X))
pred_train=mdl.predict(X[:int(X.shape[0]*0.1)],verbose=1)
pred_val=mdl.predict(X[int(X.shape[0]*0.1):],verbose=1)
'''
pred_test=mdl.predict(X_test,verbose=1)
'''

pred_trn_shrnk=(pred_train>0.7).astype(np.uint8)
pred_val_shrnk=(pred_val>0.7).astype(np.uint8)
'''
pred_tst_shrnk=(pred_test>0.5).astype(np.uint8)
'''

nwindx=random.randint(0,len(pred_trn_shrnk))
imshow(X[int(Y1.shape[0]*0.4):][nwindx])
plt.show()
imshow(Y1[int(Y1.shape[0]*0.4):][nwindx])
plt.show()
imshow(np.squeeze(pred_val_shrnk[nwindx]))
plt.show()

import seaborn as sns


FP = len(np.where(pred_val_shrnk[nwindx] - np.squeeze(Y1)  == 1)[0])
FN = len(np.where(pred_val_shrnk[nwindx] - Y1[int(Y1.shape[0]*0.0.5):][nwindx]    == -1)[0])
TP = len(np.where(pred_val_shrnk[nwindx] + Y1[int(Y1.shape[0]*0.0.5):][nwindx]  ==2)[0])
TN = len(np.where(pred_val_shrnk[nwindx] + Y1[int(Y1.shape[0]*0.0.5:)][nwindx]   == 0)[0])
cmat = [[TP, FN], [FP, TN]]

plt.figure(figsize = (6,6))
sns.heatmap(cmat/np.sum(cmat), cmap="Reds", annot=True, fmt = '.2%', square=1,   linewidth=2.)
plt.xlabel("predictions")
plt.ylabel("real values")
plt.show()

print(cmat)
print("Precision :", TP/(TP+FP)*100, "%")
sensitivity=TP/(TP+FN)
specificity=TP/(FP+TN)
print("Sensitivity :", sensitivity*100, "%")
print("Specificity :", specificity*100, "%")
print("Positive Predictive value :", TP/(TP+FP)*100, "%")
print("Negative Predictive value :", TN/(TN+FN)*100, "%")
print("False positive rate :", FP/(FP+TN)*100, "%")
print("False negative rate :", FN/(TP+FN)*100, "%")
print("Likelihood ratio positive: ",sensitivity/(1-specificity)*100, "%")
print("Likelihood ratio negative: ",((1-sensitivity)/specificity)*100, "%")

!pip install tqdm

!pip install keras

